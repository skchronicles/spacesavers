#!/usr/bin/env python3
# -*- coding: UTF-8 -*-

"""Spacesaver: find old and redundant files to optimize diskspace
About:
    This is the main entry for spacesaver.
USAGE:
	$ spacesaver <ls|df|ln> [OPTIONS]
Example:
    $ spacesaver ls -h
    $ spacesaver df -h
    $ spacesaver ln -h
"""

# Python standard library
from __future__ import print_function
from genericpath import isdir
import sys, os, textwrap, uuid

# 3rd party imports from pypi
import argparse  # potential python3 3rd party package, added in python/3.5

# Local imports  
from src.shells import bash
from src.commands import _ls, _df, _ln
from src.utils import (initialize,
    err,
    exists,
    fatal,
    permissions,
    require)

__version__ = 'v1.0.0'


def ls(sub_args):
    """Recursively list information about files and directories
    @param sub_args <parser.parse_args() object>:
        Parsed arguments for run sub-command
    """
    # Column names of file listing
    header = ['Inode', 'Permissions', 'Owner', 'Group', 'Bytes', 
            'Size', 'MDate', 'Age', 'File', 'NDuplicates', 'BDuplicates', 
            'SDuplicates', 'DOwners', 'Duplicates']
    
    # Display information about duplicate files
    print('\t'.join(header))
    for path in sub_args.DIRECTORY:
        for file_listing in _ls(path):
            print('\t'.join(file_listing))

    return


def df(sub_args):
    """Report file system disk space usage
    @param sub_args <parser.parse_args() object>:
        Parsed arguments for run sub-command
    """
    # Column names of file listing
    header = ['Path', 'FolderOwner', 'FileCoOwners', 'Duplicated', 'Duplicated_Bytes', 'Used', '%Duplicated', 'wAgeS', 'wDupS', 'wOccS', 'Score']
    print('\t'.join(header))

    # Check for standard input 
    if not sys.stdin.isatty():
        header = next(sys.stdin)
        # Read from standard input
        df_listing = _df(sys.stdin, sub_args.DIRECTORY[0], True)
        print('\t'.join(df_listing))
        
        return

    # Display information about duplicate files
    for path in sub_args.DIRECTORY:
        if path:
            df_listing = _df(_ls(path), path)
            print('\t'.join(df_listing))
    
    return


def ln(sub_args):
    """Make hard links between duplicated files 
    @param sub_args <parser.parse_args() object>:
        Parsed arguments for run sub-command
    """
    minsize = int(sub_args.m)
    for path in sub_args.DIRECTORY:
        if path:
            for mastercopy, duplicate in _ln(path, minsize):
                # mastercopy is the oldest occurence in a set
                # of duplciated files. The _ln() function will
                # not yield tuples if the user does not own the
                # at least two duplicated files, i.e. the user
                # will always own mastercopy and duplicate.
                if exists(mastercopy) and exists(duplicate):
                    # Keeps track of the status of linking
                    # step in the deduplication process.
                    linked = False
                    dup_uuid = ".spacesaver_ln.{}".format(str(uuid.uuid4()))
                    dup_tmp = "{}{}".format(duplicate, dup_uuid)
                    try:
                        # Rename the dest of the symlink, i.e. 
                        # the duplicate file prior to creating
                        # the hard link. This enables a quick
                        # restoring method if an error occurs
                        # and avoids filename collisions.
                        # Example: a.dup.txt -> a.dup.txt.spacesaver_ln.12abc34-ae42nnn
                        os.rename(duplicate, dup_tmp)
                        # Create a hardlink from the master
                        # copy with the original file name 
                        # of the duplicate file, it is now 
                        # possible after renaming the dup
                        # file as there are no collisions
                        # between the originial duplicate
                        # filename and the destination
                        # of the hard link.
                        os.link(mastercopy, duplicate)
                        linked = True
                        # Delete the tmp renamed duplicate 
                        # file, the newly created hard link
                        # replaces this file. 
                        os.remove(dup_tmp)
                    except Exception as e:
                        # Restore the originial duplicated file
                        # from the renamed tmp duplicate file, i.e. 
                        # Example: a.dup.txt.spacesaver_ln.12abc34-ae42nnn -> a.dup.txt
                        if linked:
                            # Remove hard link from master copy 
                            os.unlink(duplicate)
                        
                        # Restore the original duplicate file 
                        # to its originial state.
                        os.rename(duplicate, dup_tmp)

                        err('WARNING: Failed to create hard link "{}" error!'.format(
                        "{} -> {}".format(duplicate, mastercopy), e))
                        continue   # go to next file
    return


def parsed_arguments():
    """Parses user-provided command-line arguments. Requires argparse and textwrap
    package. argparse was added to standard lib in python 3.5 and textwrap was added
    in python 3.5. To create custom help formatting for subparsers a docstring is
    used create the help message for required options. argparse does not support named
    subparser groups, which is normally what would be used to accomphish this reformatting.
    As so, the help message for require options must be suppressed. If a new required arg
    is added to a subparser, it must be added to the docstring and the usage statement
    also must be updated.
    """

    # Create a top-level parser
    parser = argparse.ArgumentParser(description = 'optimize your disk space utilization')

    # Adding Verison information
    parser.add_argument('--version', action = 'version', version='%(prog)s {}'.format(__version__))

    # Create sub-command parser
    subparsers = parser.add_subparsers(help='List of available sub-commands')

    # Options for the "ls" sub-command
    # Grouped sub-parser arguments are currently not supported.
    # https://bugs.python.org/issue9341
    # Here is a work around to create more useful help message for named
    # options that are required! Please note: if a required arg is added the
    # description below should be updated (i.e. update usage and add new option)
    required_ls_options = textwrap.dedent("""\
        usage: 
          spacesaver ls [-h] DIRECTORY [DIRECTORY ...]

          List the contents of one or more directories to
        find duplicate files. Recusively lists information
        about the files and directories in a set of given
        paths.
        
          To reduce overall strain on the file system and
        runtime, a set of heuristics are used to filter a list
        of candidate duplicates prior to running computionally
        expensive steps. And as so, before calculating an MD5
        checksum of the entire file, potential duplicates are
        identifed by matching their file sizes and the checksum
        of the file's first 64 KiB chunk.

          Please note that this sub command may take a while
        to process depending on the shear number or the size
        of files existing in a given subtree. Also symlinks or 
        multiple occurences of hardlinks will be skipped over
        as these files do not take up any appreciable disk 
        space.

        """)

    # Display example usage in epilog
    ls_epilog = textwrap.dedent("""\
        example:
          # List raw data directory contents
          $ spacesaver ls /data/CCBR/rawdata/ccbr123/

        version:
          {}
        """.format(__version__))

    # Supressing help message of required args to overcome no sub-parser named groups
    subparser_ls = subparsers.add_parser('ls',
        help = 'Recusively list directory contents',
        usage = argparse.SUPPRESS,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description = required_ls_options,
        epilog = ls_epilog
    )

    # Positional arguments
    subparser_ls.add_argument('DIRECTORY', 
        # Check if the file exists and if it is readable
        type = lambda file: permissions(parser, file, os.R_OK),
        nargs = '+',
        help = argparse.SUPPRESS
    )

    # Options for the "df" sub-command
    # Grouped sub-parser arguments are currently not supported by argparse.
    # https://bugs.python.org/issue9341
    # Here is a work around to create more useful help message for named
    # options that are required! Please note: if a required arg is added the
    # description below should be updated (i.e. update usage and add new option)
    required_df_options = textwrap.dedent("""\
        usage: 
          spacesaver df [-h] DIRECTORY [DIRECTORY ...]

          Reports duplicated disk space usage for one or
        more directories. A duplication rate or score is
        calculated for each of the provided paths to assess
        the amount of redudant data in a given location. 
        
          Please note that this sub command may take a while
        to process depending on the shear number or the size
        of files existing in a given subtree. To assess the 
        number or size of files that exist in a provided
        directory, please run the 'spacesaver ls' prior to
        running 'spacesaver df'.
        
          The 'spacesaver df' sub command also recognizes
        standard input from the 'spacespacer ls' sub command.
        And as so, an output file from the spacesaver ls sub
        command can be piped into the df subcommand. 

        """)

    # Display example usage in epilog
    df_epilog = textwrap.dedent("""\
        example:
          # Assess disk space usage of a directory
          $ spacesaver df /data/ccbr123/

          # Use output from ls sub command as input
          $ spacesaver ls /data/ccbr123/ > ls.out
          $ cat ls.out | spacesaver df /data/ccbr123/

        version:
          {}
        """.format(__version__))

    # Supressing help message of required args to overcome no sub-parser named groups
    subparser_df = subparsers.add_parser('df',
        help = 'Report duplication rate and disk space usage',
        usage = argparse.SUPPRESS,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description = required_df_options,
        epilog = df_epilog
    )

    # Positional arguments
    subparser_df.add_argument('DIRECTORY', 
        # Check if the standard input or provided path exists and if it is readable
        type = lambda file: permissions(parser, file, os.R_OK),
        nargs = '+',
        help = argparse.SUPPRESS
    )

    # Options for the "ln" sub-command
    # Grouped sub-parser arguments are currently not supported by argparse.
    # https://bugs.python.org/issue9341
    # Here is a work around to create more useful help message for named
    # options that are required! Please note: if a required arg is added the
    # description below should be updated (i.e. update usage and add new option)
    required_ln_options = textwrap.dedent("""\
        usage: 
          spacesaver ln [-h] [-m] DIRECTORY [DIRECTORY ...]

          Make hard links between duplicated files in one
        or more directories. Hard links point to the same 
        inode on a device or file system, and do not take 
        up any appreciable disk space. A significant amount
        of disk space can be recovered or saved by replacing
        duplicated files with hard links.

          Hard links come with a few caveats! Please read 
        through the section below to understand any issues
        that can a rise when creating multiple hard links:
          * Hard links cannot be created across different 
             devices, volumes, or file systems.
          * Some file systems do not support multiple hard
             links, such as FAT; however, most modern POSIX
             complaint operating systems such as linux or 
             macOS support this feature.
          * Creating multiple hard links has the effect 
             of giving one file multiple names. From the
             file system's perspective, they are all the 
             same. Each hard link will independently point
             to the same data on disk. 
          * If you update one hard link, the changes will 
             propagate to all the other hard links. This 
             causes an alias effect which can lead to
             desired or even catastrophic results.

          Disclaimer: use a healthy amount of caution and 
        common sense when running this command! Treat it 
        with the same respect as an rm command. If you do 
        not fully understand the conditions described above, 
        you should not run 'spacesaver ln'. The '-m' option
        can be used to set a minimum file size in bytes. If
        a file does not exceed this minimum file size, then a
        hard link will not be created!
        
          Please note that this sub command may take a while
        to process depending on the shear number or the size
        of files existing in a given subtree. To assess the 
        number or size of files that exist in a provided
        directory, please run the 'spacesaver ls' prior to
        running 'spacesaver ln'.

        """)

    # Display example usage in epilog
    ln_epilog = textwrap.dedent("""\
        example:
          # Create hard links between duplicate files
          $ spacesaver ln /data/ccbr123/

        version:
          {}
        """.format(__version__))

    # Supressing help message of required args to overcome no sub-parser named groups
    subparser_ln = subparsers.add_parser('ln',
        help = 'Make hard links between duplicated files',
        usage = argparse.SUPPRESS,
        formatter_class=argparse.RawTextHelpFormatter,
        description = required_ln_options,
        epilog = ln_epilog
    )

    # Positional arguments
    subparser_ln.add_argument('DIRECTORY', 
        # Check if the provided path exists and if it is readable
        type = lambda file: permissions(parser, file, os.R_OK),
        nargs = '+',
        help = argparse.SUPPRESS
    )

    # Options 
    # Minimum file size to create hard link
    subparser_ln.add_argument('-m',
      metavar='MINSIZE',
      type = int,
      required = False,
      default = 10485760,
      help = textwrap.dedent("""\
      Minimum size of a file in bytes.
      To create a hard link, the size 
      of a the duplicated file must 
      exceed this value.
      Default: 10485760
      """)
    )

    # Sanity check for user command line arguments 
    if len(sys.argv) < 2:
        parser.error("""\n\t └── Fatal: failed to provide a valid sub command to spacesaver!
             Please run 'spacespacer  -h' to view more information about its correct usage.""".format(
                sys.argv[0])
        )

    # Define handlers for each sub-parser
    subparser_ls.set_defaults(func = ls)
    subparser_df.set_defaults(func = df)
    subparser_ln.set_defaults(func = ln)

    # Parse command-line args
    args = parser.parse_args()
    return args


def main():

    # Collect args for sub-command
    args = parsed_arguments()

    # Mediator to call sub-command's set handler function
    args.func(args)


if __name__ == '__main__':
    main()
